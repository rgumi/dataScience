{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seminarpaper",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rgumi/dataScience/blob/master/seminarpaper-xgb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rrQrTCrhbO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pre processing\n",
        "from scipy.stats import randint, uniform\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "import datetime as dt\n",
        "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import xgboost as xgb\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "from sklearn.model_selection import cross_validate, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, make_scorer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAW5xaxrnqxF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f58a9672-8309-4eb0-b112-4ccbdc49e046"
      },
      "source": [
        "# setup\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/saschaschworm/big-data-and-data-science/master/datasets/prediction-challenge/dataset.csv')\n",
        "X, y = data.iloc[:, 1:-1], data['success']\n",
        "X['date'] = pd.to_timedelta(pd.to_datetime(X['date'])).dt.days\n",
        "\n",
        "hyperparams = { 'random_state': 1909,\n",
        "                'nthread': -1\n",
        "}\n",
        "model = xgb.XGBClassifier()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py:208: FutureWarning: Passing datetime64-dtype data to TimedeltaIndex is deprecated, will raise a TypeError in a future version\n",
            "  return func(*args, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WydWwqETnep3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pipeline\n",
        "categorical_features = ['marital_status', 'education', 'job', 'credit_default', 'housing_loan', 'personal_loan', 'communication_type', 'previous_conversion']\n",
        "numeric_features = ['date', 'age', 'n_contacts_campaign', 'days_since_last_contact', 'n_contacts_before']\n",
        "\n",
        "numeric_transformer = Pipeline([\n",
        "    ('scaler', MinMaxScaler()),\n",
        "])\n",
        "categorical_transformer = Pipeline ([\n",
        "    ('onehotencoder', OrdinalEncoder())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('n_transformer', numeric_transformer, numeric_features),\n",
        "    ('c_transformer', categorical_transformer, categorical_features),\n",
        "])\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', model)\n",
        "])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8h4MCjsnXBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# randomized hyperparameter search\n",
        "custom_scorer = make_scorer(f1_score, pos_label='Yes')\n",
        "n_estimators = randint(200, 400)\n",
        "max_depth = randint(50, 120)\n",
        "learning_rate = 0.0002\n",
        "\n",
        "param_distributions = { 'model__n_estimators': n_estimators, \n",
        "                        'model__max_depth': max_depth\n",
        "}\n",
        "\n",
        "# rs = RandomizedSearchCV(pipeline, param_distributions=param_distributions, n_iter=5,\n",
        "#                       scoring=custom_scorer, n_jobs=-1, iid=False, cv=10, random_state=1909)\n",
        "\n",
        "# rs = rs.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGEibMYUnRQy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "7b0fa8e4-c10f-4f92-bc42-a6390a1fab0c"
      },
      "source": [
        "# run optimized model\n",
        "hyperparams = { 'random_state': 1909,\n",
        "                'learning_rate': learning_rate,\n",
        "                'max_depth': 500, # rs.best_params_['model__max_depth'],\n",
        "                'n_estimators': 400, # rs.best_params_['model__n_estimators'],\n",
        "                'nthread': -1,\n",
        "                'subsample': 1,\n",
        "                'colsample_bytree': 1,\n",
        "                'objective': 'binary:logistic',\n",
        "                'gamma': 0,\n",
        "                'reg_alpha': 0,\n",
        "                'reg_lambda': 1\n",
        "            }\n",
        "model = xgb.XGBClassifier(**hyperparams)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor), \n",
        "    ('model', model)\n",
        "])\n",
        "pipeline.fit(X, y)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('preprocessor',\n",
              "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
              "                                   sparse_threshold=0.3,\n",
              "                                   transformer_weights=None,\n",
              "                                   transformers=[('n_transformer',\n",
              "                                                  Pipeline(memory=None,\n",
              "                                                           steps=[('scaler',\n",
              "                                                                   MinMaxScaler(copy=True,\n",
              "                                                                                feature_range=(0,\n",
              "                                                                                               1)))],\n",
              "                                                           verbose=False),\n",
              "                                                  ['date', 'age',\n",
              "                                                   'n_contacts_campaign',\n",
              "                                                   'days_since_last_contact',\n",
              "                                                   'n_contacts_before'])...\n",
              "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                               colsample_bylevel=1, colsample_bynode=1,\n",
              "                               colsample_bytree=1, gamma=0,\n",
              "                               learning_rate=0.0002, max_delta_step=0,\n",
              "                               max_depth=500, min_child_weight=1, missing=None,\n",
              "                               n_estimators=400, n_jobs=1, nthread=-1,\n",
              "                               objective='binary:logistic', random_state=1909,\n",
              "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "                               seed=None, silent=None, subsample=1,\n",
              "                               verbosity=1))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRYFhgewnOFk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "03a8b915-43ea-4999-8802-cb353e2307a6"
      },
      "source": [
        "# validating\n",
        "res_cv = cross_validate(pipeline, X, y, scoring=custom_scorer, cv=10, return_train_score=True)\n",
        "res_f1_tr = np.mean(res_cv['train_score']) * 100\n",
        "res_f1_te = np.mean(res_cv['test_score']) * 100\n",
        "print(hyperparams)\n",
        "print(f'Average F1 on Training and Test Sets: {res_f1_tr:.2f}%/{res_f1_te:.2f}%')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'random_state': 1909, 'learning_rate': 0.0002, 'max_depth': 500, 'n_estimators': 400, 'nthread': -1, 'subsample': 1, 'colsample_bytree': 1, 'objective': 'binary:logistic', 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 1}\n",
            "Average F1 on Training and Test Sets: 55.24%/36.48%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}