{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seminarpaper",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rgumi/dataScience/blob/master/seminarpaper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rrQrTCrhbO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pre processing\n",
        "from scipy.stats import randint, uniform\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "import datetime as dt\n",
        "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "from sklearn.model_selection import cross_validate, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, make_scorer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD1k5aRSUS4M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7671aa65-dd35-4c05-b0dc-9600e28c9f9e"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAW5xaxrnqxF",
        "colab_type": "code",
        "outputId": "bbea30b8-64e7-4dde-d6d6-50d3a5bdd8ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# setup\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/saschaschworm/big-data-and-data-science/master/datasets/prediction-challenge/dataset.csv')\n",
        "X, y = data.iloc[:, 1:-1], data['success']\n",
        "X['date'] = pd.to_timedelta(pd.to_datetime(X['date'])).dt.days\n",
        "\n",
        "hyperparams = { 'random_state': 1909}\n",
        "# model = xgb.XGBClassifier()\n",
        "model = RandomForestClassifier(**hyperparams)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py:208: FutureWarning: Passing datetime64-dtype data to TimedeltaIndex is deprecated, will raise a TypeError in a future version\n",
            "  return func(*args, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WydWwqETnep3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pipeline\n",
        "categorical_features = ['marital_status', 'education', 'job', 'credit_default', 'housing_loan', 'personal_loan', 'communication_type', 'previous_conversion']\n",
        "numeric_features = ['date', 'age', 'n_contacts_campaign', 'days_since_last_contact', 'n_contacts_before']\n",
        "\n",
        "numeric_transformer = Pipeline([\n",
        "    ('scaler', MinMaxScaler()),\n",
        "])\n",
        "categorical_transformer = Pipeline ([\n",
        "    ('onehotencoder', OrdinalEncoder())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('n_transformer', numeric_transformer, numeric_features),\n",
        "    ('c_transformer', categorical_transformer, categorical_features),\n",
        "])\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', model)\n",
        "])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8h4MCjsnXBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# randomized hyperparameter search\n",
        "custom_scorer = make_scorer(f1_score, pos_label='Yes')\n",
        "n_estimators = randint(250, 400)\n",
        "max_depth = randint(10, 80)\n",
        "learning_rate = 0.002\n",
        "\n",
        "param_distributions = { 'model__n_estimators': n_estimators, \n",
        "                        'model__max_depth': max_depth\n",
        "}\n",
        "\n",
        "# rs = RandomizedSearchCV(pipeline, param_distributions=param_distributions, n_iter=5,\n",
        "#                       scoring=custom_scorer, n_jobs=-1, iid=False, cv=10, random_state=1909)\n",
        "\n",
        "# rs = rs.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGEibMYUnRQy",
        "colab_type": "code",
        "outputId": "a0d079f5-2089-4906-8d3b-a941f96ca3f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "# run optimized model\n",
        "hyperparams = { 'random_state': 1909,\n",
        "                'learning_rate': learning_rate,\n",
        "                'max_depth': 40, # rs.best_params_['model__max_depth'],\n",
        "                'n_estimators': 120, # rs.best_params_['model__n_estimators'],\n",
        "                'nthread': -1,\n",
        "                'subsample': 1,\n",
        "                'colsample_bytree': 1,\n",
        "                'objective': 'binary:logistic',\n",
        "                'gamma': 0,\n",
        "                'reg_alpha': 0,\n",
        "                'reg_lambda': 1\n",
        "}\n",
        "  \n",
        "hyperparams = { 'n_estimators': 300, # rs.best_params_['model__n_estimators'], \n",
        "                'criterion': 'gini', \n",
        "                'max_features': 0.6, # testing from 0.3 to 0.6 => did like 20% \n",
        "                'max_depth': 100, # rs.best_params_['model__max_depth'], || testing from 10 to 50 => again 20% better || from 50 to 100 =>\n",
        "                'min_samples_split': 2,\n",
        "                'min_samples_leaf': 2,  # didnt change much!\n",
        "                'min_weight_fraction_leaf': 0.0,\n",
        "                'max_leaf_nodes': None,\n",
        "                'min_impurity_decrease': 0.0,\n",
        "                'min_impurity_split': None,\n",
        "                'bootstrap': True,\n",
        "                'oob_score': False,\n",
        "                'n_jobs': -1, \n",
        "                'random_state': 1909,\n",
        "                'verbose': 0,\n",
        "                'warm_start': False,\n",
        "                'class_weight': None\n",
        "}\n",
        "model = RandomForestClassifier(**hyperparams)\n",
        "# model = xgb.XGBClassifier(**hyperparams)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor), \n",
        "    ('model', model)\n",
        "])\n",
        "pipeline.fit(X, y)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('preprocessor',\n",
              "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
              "                                   sparse_threshold=0.3,\n",
              "                                   transformer_weights=None,\n",
              "                                   transformers=[('n_transformer',\n",
              "                                                  Pipeline(memory=None,\n",
              "                                                           steps=[('scaler',\n",
              "                                                                   MinMaxScaler(copy=True,\n",
              "                                                                                feature_range=(0,\n",
              "                                                                                               1)))],\n",
              "                                                           verbose=False),\n",
              "                                                  ['date', 'age',\n",
              "                                                   'n_contacts_campaign',\n",
              "                                                   'days_since_last_contact',\n",
              "                                                   'n_contacts_before'])...\n",
              "                ('model',\n",
              "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
              "                                        criterion='gini', max_depth=100,\n",
              "                                        max_features=0.6, max_leaf_nodes=None,\n",
              "                                        min_impurity_decrease=0.0,\n",
              "                                        min_impurity_split=None,\n",
              "                                        min_samples_leaf=2, min_samples_split=2,\n",
              "                                        min_weight_fraction_leaf=0.0,\n",
              "                                        n_estimators=300, n_jobs=-1,\n",
              "                                        oob_score=False, random_state=1909,\n",
              "                                        verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRYFhgewnOFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# validating\n",
        "res_cv = cross_validate(pipeline, X, y, scoring=custom_scorer, cv=10, return_train_score=True)\n",
        "res_f1_tr = np.mean(res_cv['train_score']) * 100\n",
        "res_f1_te = np.mean(res_cv['test_score']) * 100\n",
        "print(hyperparams)\n",
        "print(f'Average F1 on Training and Test Sets: {res_f1_tr:.2f}%/{res_f1_te:.2f}%')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}